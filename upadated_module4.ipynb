{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d934fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (34993, 62)\n",
      "\n",
      "Class distribution:\n",
      "habitable_label\n",
      "0    34756\n",
      "1      237\n",
      "Name: count, dtype: int64\n",
      "\n",
      "MODEL EVALUATION (TEST DATA)\n",
      "--------------------------------\n",
      "Accuracy : 0.7992951038293008\n",
      "Precision: 0.028703703703703703\n",
      "Recall   : 0.8732394366197183\n",
      "F1-score : 0.055580457194083374\n",
      "ROC-AUC  : 0.913392506183162\n",
      "\n",
      "CROSS-VALIDATION ROC-AUC\n",
      "--------------------------------\n",
      "CV Scores: [0.85735928 0.89224872 0.91663669 0.92334487 0.8864636 ]\n",
      "Mean CV ROC-AUC: 0.8952106334701109\n",
      "Std CV ROC-AUC : 0.023531341307247124\n",
      "\n",
      "Top 10 Ranked Exoplanets:\n",
      "                  pl_name  habitability_probability\n",
      "33591        TRAPPIST-1 h                  0.988017\n",
      "33571        TRAPPIST-1 d                  0.987990\n",
      "33577        TRAPPIST-1 e                  0.987743\n",
      "33581        TRAPPIST-1 f                  0.987524\n",
      "33565        TRAPPIST-1 c                  0.987500\n",
      "33564        TRAPPIST-1 b                  0.987452\n",
      "33586        TRAPPIST-1 g                  0.987376\n",
      "14157       Kepler-1649 b                  0.986897\n",
      "14167       Kepler-1649 c                  0.986824\n",
      "33605  Teegarden's Star b                  0.986438\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "\n",
    "# STEP 1: Load Dataset\n",
    "\n",
    "df = pd.read_csv(\"exoplanets_clean_full.csv\")\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "\n",
    "\n",
    "# STEP 2: Create Binary Habitability Label (Rule-based)\n",
    "\n",
    "df[\"habitable_label\"] = (\n",
    "    (df[\"pl_eqt\"].between(230, 330)) &\n",
    "    (df[\"pl_rade\"].between(0.9, 2.2))\n",
    ").astype(int)\n",
    "\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df[\"habitable_label\"].value_counts())\n",
    "\n",
    "\n",
    "# STEP 3: Select RAW Features (No Leakage)\n",
    "\n",
    "FEATURES = [\n",
    "    \"pl_rade\",\n",
    "    \"pl_bmasse\",\n",
    "    \"pl_orbper\",\n",
    "    \"pl_orbsmax\",\n",
    "    \"st_teff\",\n",
    "    \"st_rad\",\n",
    "    \"sy_dist\"\n",
    "]\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[\"habitable_label\"]\n",
    "\n",
    "\n",
    "# STEP 4: Trainâ€“Test Split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "# STEP 5: Feature Scaling \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# STEP 6: Train Regularized Logistic Regression \n",
    "\n",
    "lr = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    C=0.3,                      # Strong regularization\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"liblinear\",\n",
    "    max_iter=5000\n",
    ")\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# STEP 7: Evaluation on Test Data\n",
    "\n",
    "y_pred  = lr.predict(X_test)\n",
    "y_prob  = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nMODEL EVALUATION (TEST DATA)\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred))\n",
    "print(\"F1-score :\", f1_score(y_test, y_pred))\n",
    "print(\"ROC-AUC  :\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "\n",
    "# STEP 8: Cross-Validation \n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    lr,\n",
    "    scaler.fit_transform(X),\n",
    "    y,\n",
    "    cv=cv,\n",
    "    scoring=\"roc_auc\"\n",
    ")\n",
    "\n",
    "print(\"\\nCROSS-VALIDATION ROC-AUC\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"CV Scores:\", cv_scores)\n",
    "print(\"Mean CV ROC-AUC:\", cv_scores.mean())\n",
    "print(\"Std CV ROC-AUC :\", cv_scores.std())\n",
    "\n",
    "\n",
    "# STEP 9: Rank Exoplanets by Habitability Probability\n",
    "\n",
    "df[\"habitability_probability\"] = lr.predict_proba(\n",
    "    scaler.transform(X)\n",
    ")[:, 1]\n",
    "\n",
    "ranked_exoplanets = (\n",
    "    df.sort_values(\"habitability_probability\", ascending=False)\n",
    "      .drop_duplicates(\"pl_name\")\n",
    "      [[\"pl_name\", \"habitability_probability\"]]\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 Ranked Exoplanets:\")\n",
    "print(ranked_exoplanets.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14365069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Evaluation\n",
      "-------------------------\n",
      "Accuracy : 0.9859020765860164\n",
      "Precision: 0.3225806451612903\n",
      "Recall   : 0.9859154929577465\n",
      "F1-score : 0.4861111111111111\n",
      "ROC-AUC  : 0.9981048658885316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Train Random Forest (regularized)\n",
    "# ------------------------------------------------------------\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    min_samples_leaf=20,\n",
    "    min_samples_split=30,\n",
    "    max_features=0.6,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Evaluate on TEST data\n",
    "# ------------------------------------------------------------\n",
    "rf_preds = rf.predict(X_test)\n",
    "rf_probs = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_preds)\n",
    "\n",
    "print(\"Random Forest Evaluation\")\n",
    "print(\"-------------------------\")\n",
    "print(\"Accuracy :\", rf_accuracy)\n",
    "print(\"Precision:\", precision_score(y_test, rf_preds))\n",
    "print(\"Recall   :\", recall_score(y_test, rf_preds))\n",
    "print(\"F1-score :\", f1_score(y_test, rf_preds))\n",
    "print(\"ROC-AUC  :\", roc_auc_score(y_test, rf_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f492c7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŒ² Random Forest Evaluation\n",
      "--------------------------------\n",
      "Accuracy : 0.9859020765860164\n",
      "Precision: 0.3225806451612903\n",
      "Recall   : 0.9859154929577465\n",
      "F1-score : 0.4861111111111111\n",
      "ROC-AUC  : 0.9981048658885316\n",
      "\n",
      "ðŸ“Š Logistic Regression Evaluation\n",
      "--------------------------------\n",
      "Accuracy : 0.7992951038293008\n",
      "Precision: 0.028703703703703703\n",
      "Recall   : 0.8732394366197183\n",
      "F1-score : 0.055580457194083374\n",
      "ROC-AUC  : 0.913392506183162\n",
      "\n",
      "ðŸš€ XGBoost (Binary) Evaluation\n",
      "--------------------------------\n",
      "Accuracy : 0.9982853876928939\n",
      "Precision: 0.9206349206349206\n",
      "Recall   : 0.8169014084507042\n",
      "F1-score : 0.8656716417910447\n",
      "ROC-AUC  : 0.9995650511875319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# MODEL 1: Random Forest (Binary Classification)\n",
    "# ============================================================\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    min_samples_leaf=20,\n",
    "    min_samples_split=30,\n",
    "    max_features=0.6,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_preds = rf.predict(X_test)\n",
    "rf_probs = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nðŸŒ² Random Forest Evaluation\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, rf_preds))\n",
    "print(\"Precision:\", precision_score(y_test, rf_preds))\n",
    "print(\"Recall   :\", recall_score(y_test, rf_preds))\n",
    "print(\"F1-score :\", f1_score(y_test, rf_preds))\n",
    "print(\"ROC-AUC  :\", roc_auc_score(y_test, rf_probs))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MODEL 2: Logistic Regression (Baseline, Realistic)\n",
    "# ============================================================\n",
    "lr = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    C=0.3,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"liblinear\",\n",
    "    max_iter=5000\n",
    ")\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr_preds = lr.predict(X_test)\n",
    "lr_probs = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nðŸ“Š Logistic Regression Evaluation\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, lr_preds))\n",
    "print(\"Precision:\", precision_score(y_test, lr_preds))\n",
    "print(\"Recall   :\", recall_score(y_test, lr_preds))\n",
    "print(\"F1-score :\", f1_score(y_test, lr_preds))\n",
    "print(\"ROC-AUC  :\", roc_auc_score(y_test, lr_probs))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MODEL 3: XGBoost (Binary Classification)\n",
    "# ============================================================\n",
    "xgb_bin = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    n_estimators=150,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=2.0,\n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "\n",
    "xgb_bin.fit(X_train, y_train)\n",
    "\n",
    "xgb_preds = xgb_bin.predict(X_test)\n",
    "xgb_probs = xgb_bin.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nðŸš€ XGBoost (Binary) Evaluation\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, xgb_preds))\n",
    "print(\"Precision:\", precision_score(y_test, xgb_preds))\n",
    "print(\"Recall   :\", recall_score(y_test, xgb_preds))\n",
    "print(\"F1-score :\", f1_score(y_test, xgb_preds))\n",
    "print(\"ROC-AUC  :\", roc_auc_score(y_test, xgb_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edf3409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŒ² Random Forest (Balanced Evaluation)\n",
      "-------------------------------------\n",
      "Accuracy : 0.9788732394366197\n",
      "Precision: 0.9722222222222222\n",
      "Recall   : 0.9859154929577465\n",
      "F1-score : 0.9790209790209791\n",
      "ROC-AUC  : 0.9986113866296369\n",
      "\n",
      "ðŸ“Š Logistic Regression (Balanced Evaluation)\n",
      "-------------------------------------------\n",
      "Accuracy : 0.852112676056338\n",
      "Precision: 0.8378378378378378\n",
      "Recall   : 0.8732394366197183\n",
      "F1-score : 0.8551724137931035\n",
      "ROC-AUC  : 0.931362824836342\n",
      "\n",
      "ðŸš€ XGBoost (Balanced Evaluation)\n",
      "--------------------------------\n",
      "Accuracy : 0.9084507042253521\n",
      "Precision: 1.0\n",
      "Recall   : 0.8169014084507042\n",
      "F1-score : 0.8992248062015504\n",
      "ROC-AUC  : 0.9998016266613767\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "import joblib\n",
    "# ============================================================\n",
    "# STEP 1: CREATE A BALANCED TEST SET (EVALUATION ONLY)\n",
    "# ============================================================\n",
    "\n",
    "X_test_0 = X_test[y_test == 0]\n",
    "X_test_1 = X_test[y_test == 1]\n",
    "\n",
    "y_test_0 = y_test[y_test == 0]\n",
    "y_test_1 = y_test[y_test == 1]\n",
    "\n",
    "# Downsample majority class\n",
    "X_test_0_down, y_test_0_down = resample(\n",
    "    X_test_0,\n",
    "    y_test_0,\n",
    "    replace=False,\n",
    "    n_samples=len(y_test_1),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Balanced test data\n",
    "X_test_bal = np.vstack((X_test_0_down, X_test_1))\n",
    "y_test_bal = np.hstack((y_test_0_down, y_test_1))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MODEL 1: Random Forest (Balanced Evaluation)\n",
    "# ============================================================\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    min_samples_leaf=20,\n",
    "    min_samples_split=30,\n",
    "    max_features=0.6,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_probs = rf.predict_proba(X_test_bal)[:, 1]\n",
    "rf_preds = (rf_probs >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nðŸŒ² Random Forest (Balanced Evaluation)\")\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test_bal, rf_preds))\n",
    "print(\"Precision:\", precision_score(y_test_bal, rf_preds))\n",
    "print(\"Recall   :\", recall_score(y_test_bal, rf_preds))\n",
    "print(\"F1-score :\", f1_score(y_test_bal, rf_preds))\n",
    "print(\"ROC-AUC  :\", roc_auc_score(y_test_bal, rf_probs))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MODEL 2: Logistic Regression (Balanced Evaluation)\n",
    "# ============================================================\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    C=0.3,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"liblinear\",\n",
    "    max_iter=5000\n",
    ")\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr_probs = lr.predict_proba(X_test_bal)[:, 1]\n",
    "lr_preds = (lr_probs >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nðŸ“Š Logistic Regression (Balanced Evaluation)\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test_bal, lr_preds))\n",
    "print(\"Precision:\", precision_score(y_test_bal, lr_preds))\n",
    "print(\"Recall   :\", recall_score(y_test_bal, lr_preds))\n",
    "print(\"F1-score :\", f1_score(y_test_bal, lr_preds))\n",
    "print(\"ROC-AUC  :\", roc_auc_score(y_test_bal, lr_probs))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MODEL 3: XGBoost (Balanced Evaluation)\n",
    "# ============================================================\n",
    "\n",
    "xgb_bin = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    n_estimators=150,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=2.0,\n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "\n",
    "xgb_bin.fit(X_train, y_train)\n",
    "\n",
    "xgb_probs = xgb_bin.predict_proba(X_test_bal)[:, 1]\n",
    "xgb_preds = (xgb_probs >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nðŸš€ XGBoost (Balanced Evaluation)\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test_bal, xgb_preds))\n",
    "print(\"Precision:\", precision_score(y_test_bal, xgb_preds))\n",
    "print(\"Recall   :\", recall_score(y_test_bal, xgb_preds))\n",
    "print(\"F1-score :\", f1_score(y_test_bal, xgb_preds))\n",
    "print(\"ROC-AUC  :\", roc_auc_score(y_test_bal, xgb_probs))\n",
    "# joblib.dump(model, \"model.pkl\")\n",
    "# print(\"model.pkl saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cefb352f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully\n",
      "model.pkl saved successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"exoplanets_clean_full.csv\")\n",
    "\n",
    "# Create habitability label (same rule as before)\n",
    "df[\"habitable_label\"] = (\n",
    "    (df[\"pl_eqt\"].between(200, 300)) &\n",
    "    (df[\"pl_rade\"].between(0.5, 2.0))\n",
    ").astype(int)\n",
    "\n",
    "# Select features\n",
    "FEATURES = [\n",
    "    \"pl_rade\",\n",
    "    \"pl_bmasse\",\n",
    "    \"pl_eqt\",\n",
    "    \"pl_orbper\",\n",
    "    \"st_teff\",\n",
    "    \"st_rad\",\n",
    "    \"st_lum\",\n",
    "    \"sy_dist\"\n",
    "]\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[\"habitable_label\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train model (simple & stable for API)\n",
    "model = LogisticRegression(\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=5000\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained successfully\")\n",
    "joblib.dump(model, \"model.pkl\")\n",
    "print(\"model.pkl saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f80df7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression(\n",
    "        class_weight=\"balanced\",\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(pipeline, \"model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ea691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f111fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# model = joblib.load(\"model.pkl\")\n",
    "\n",
    "# print(\"Model type:\", type(model))\n",
    "# print(\"Number of features expected:\", model.n_features_in_)\n",
    "# print(\"Feature names:\", getattr(model, \"feature_names_in_\", \"Not available\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c3e904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "base_model = LogisticRegression(\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "calibrated_model = CalibratedClassifierCV(\n",
    "    base_model,\n",
    "    method=\"sigmoid\",\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "calibrated_model.fit(X_train, y_train)\n",
    "joblib.dump(calibrated_model, \"model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1eb7431",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'habitability_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\k8710\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'habitability_score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m FEATURES = [\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpl_rade\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpl_bmasse\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mst_rad\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m ]\n\u001b[32m     10\u001b[39m X = df[FEATURES]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m y = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhabitability_score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     13\u001b[39m scaler = StandardScaler()\n\u001b[32m     14\u001b[39m X_scaled = scaler.fit_transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\k8710\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\k8710\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'habitability_score'"
     ]
    }
   ],
   "source": [
    "FEATURES = [\n",
    "    \"pl_rade\",\n",
    "    \"pl_bmasse\",\n",
    "    \"pl_eqt\",\n",
    "    \"pl_orbper\",\n",
    "    \"st_teff\",\n",
    "    \"st_rad\"\n",
    "]\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[\"habitability_score\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "model = XGBRegressor(...)\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "joblib.dump(model, \"model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
